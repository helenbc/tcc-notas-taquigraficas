{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting small sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_session</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>party</th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>25345</td>\n",
       "      <td>O SR. PRESIDENTE RODRIGO PACHECO</td>\n",
       "      <td>Rodrigo Pacheco. Bloco Parlamentar PSD/Republi...</td>\n",
       "      <td>Sob a proteção de Deus, iniciamos os nossos tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>25345</td>\n",
       "      <td>O SR. PRESIDENTE RODRIGO PACHECO</td>\n",
       "      <td>Rodrigo Pacheco. Bloco Parlamentar PSD/Republi...</td>\n",
       "      <td>Peço aos Srs. Senadores e às Sras. Senadoras q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>25345</td>\n",
       "      <td>O SR. OTTO ALENCAR</td>\n",
       "      <td>Bloco Parlamentar PSD/Republicanos/PSD - BA</td>\n",
       "      <td>Prometo guardar a Constituição Federal e as le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>25345</td>\n",
       "      <td>O SR. PRESIDENTE RODRIGO PACHECO</td>\n",
       "      <td>Rodrigo Pacheco. Bloco Parlamentar PSD/Republi...</td>\n",
       "      <td>Agradeço ao nobre Senador Otto Alencar e cumpr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>25345</td>\n",
       "      <td>O SR. ROGÉRIO CARVALHO</td>\n",
       "      <td>Bloco Parlamentar da Resistência Democrática/P...</td>\n",
       "      <td>Pelo Rio de Janeiro, Senador Romário.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_session                      speaker_name  \\\n",
       "168       25345  O SR. PRESIDENTE RODRIGO PACHECO   \n",
       "169       25345  O SR. PRESIDENTE RODRIGO PACHECO   \n",
       "170       25345                O SR. OTTO ALENCAR   \n",
       "171       25345  O SR. PRESIDENTE RODRIGO PACHECO   \n",
       "172       25345            O SR. ROGÉRIO CARVALHO   \n",
       "\n",
       "                                                 party  \\\n",
       "168  Rodrigo Pacheco. Bloco Parlamentar PSD/Republi...   \n",
       "169  Rodrigo Pacheco. Bloco Parlamentar PSD/Republi...   \n",
       "170        Bloco Parlamentar PSD/Republicanos/PSD - BA   \n",
       "171  Rodrigo Pacheco. Bloco Parlamentar PSD/Republi...   \n",
       "172  Bloco Parlamentar da Resistência Democrática/P...   \n",
       "\n",
       "                                                speech  \n",
       "168  Sob a proteção de Deus, iniciamos os nossos tr...  \n",
       "169  Peço aos Srs. Senadores e às Sras. Senadoras q...  \n",
       "170  Prometo guardar a Constituição Federal e as le...  \n",
       "171  Agradeço ao nobre Senador Otto Alencar e cumpr...  \n",
       "172              Pelo Rio de Janeiro, Senador Romário.  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "meetings_df = pd.read_csv('./meetings.csv')\n",
    "\n",
    "small_session_ids = []\n",
    "with open('./sizes/small_sessions.json') as f:\n",
    "    small_session_ids = json.load(f)\n",
    "\n",
    "small_sessions_df = meetings_df[meetings_df['id_session'].isin(small_session_ids)]\n",
    "small_sessions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df_to_speeches_list(text_df: pd.DataFrame):\n",
    "    speakers = text_df['speaker_name']\n",
    "    speeches = text_df['speech']\n",
    "    \n",
    "    speeches_list = \"\"\n",
    "    for index, _ in enumerate(speakers.items()):\n",
    "        speeches_list += f\"<llmlingua, compress=False>{speakers.iloc[index]}</llmlingua>: {speeches.iloc[index]}\\n\"\n",
    "    return speeches_list\n",
    "\n",
    "def get_speakers_list_from_dataframe(df):\n",
    "    return list(set(df['speaker_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarization_prompt_for_stances(context: str, dataframe):\n",
    "    speeches_list = transform_df_to_speeches_list(dataframe)\n",
    "    speakers_list = get_speakers_list_from_dataframe(dataframe)\n",
    "    speakers_string = ', '.join(speakers_list)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    {speeches_list}\n",
    "\n",
    "    Consider that it is an expert model in Stance Detection. Stance detection is the task of predicting an author's point of view on a subject of interest. A speech can represent one of four types of stance: for, against or neutral.\n",
    "For: When an author takes a stance \"for\" a subject, it means they support or advocate for it. Their speech or writing will likely include arguments, evidence, or opinions that highlight the positive aspects, benefits, or reasons to endorse the subject. For example, if the subject is a proposed policy change, someone taking a \"for\" stance might emphasize how it could improve people's lives or address important societal issues.\n",
    "Against: This stance indicates opposition or disagreement with the subject at hand. Authors taking an \"against\" stance will present arguments, evidence, or opinions that highlight flaws, risks, negative consequences, or reasons to reject the subject. Using the previous example of a proposed policy change, someone taking an \"against\" stance might argue that it would be ineffective, unfair, or harmful to certain groups.\n",
    "Neutral: A neutral stance means the author does not express explicit support or opposition towards the subject. They may present information, analysis, or perspectives in a balanced and objective manner without advocating for or against the subject. Neutral stances typically avoid strong opinions or judgments and instead focus on providing a comprehensive understanding of the topic without bias. If the person doesn't say anything about that topic, it means that they should not be listed.\n",
    "Reply in json format with the following keys: list_latent_topics, stances and summary.\n",
    "list_latent_topics: should contain the list of all topics discussed in the text, and a short description for each topic.\n",
    "stances: for each latent_topics key should contain the list of classification of the related speaker's speechs.\n",
    "summary: should contain the summary of the text.\n",
    "    Consider that you will receive as input a text with a set of speeches that make up ```{context}```.\n",
    "\n",
    "    Do the following actions for the text:\n",
    "    - Determine the all topics being discussed in the text and a brief descriptions of these topics.\n",
    "    - For each topic and for each speaker, except if the person doesn't say anything about that topic, classify the stance as being FOR, AGAINST, NEUTRAL. Being the following speakers: {speakers_string}.\n",
    "    - Before your response, translate the summary and the topics to portuguese.\n",
    "   \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send to GPT 3.5 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /home/helen/.local/lib/python3.10/site-packages (1.14.1)\n",
      "Requirement already satisfied: sniffio in /home/helen/.local/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/helen/.local/lib/python3.10/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/helen/.local/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/helen/.local/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/helen/.local/lib/python3.10/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/helen/.local/lib/python3.10/site-packages (from openai) (2.6.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/helen/.local/lib/python3.10/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/helen/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/helen/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: httpcore==1.* in /home/helen/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: certifi in /home/helen/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/helen/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/helen/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/helen/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_completion(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        n=1,\n",
    "        stream=False,\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "    content_json = json.loads(content)\n",
    "\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        'response': content_json,\n",
    "        'response_elapsed_time': elapsed_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session 25345 started!\n",
      "Processing prompt 25345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session 25345 compressed!\n",
      "1 / 41 completed!\n",
      "Processed prompt 25345 in 6 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25347 started!\n",
      "Processing prompt 25347\n",
      "Session 25347 compressed!\n",
      "2 / 41 completed!\n",
      "Processed prompt 25347 in 18 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25334 started!\n",
      "Processing prompt 25334\n",
      "Session 25334 compressed!\n",
      "3 / 41 completed!\n",
      "Processed prompt 25334 in 13 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25395 started!\n",
      "Processing prompt 25395\n",
      "Session 25395 compressed!\n",
      "4 / 41 completed!\n",
      "Processed prompt 25395 in 9 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25449 started!\n",
      "Processing prompt 25449\n",
      "Session 25449 compressed!\n",
      "5 / 41 completed!\n",
      "Processed prompt 25449 in 11 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25490 started!\n",
      "Processing prompt 25490\n",
      "Session 25490 compressed!\n",
      "6 / 41 completed!\n",
      "Processed prompt 25490 in 16 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25502 started!\n",
      "Processing prompt 25502\n",
      "Session 25502 compressed!\n",
      "7 / 41 completed!\n",
      "Processed prompt 25502 in 8 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25515 started!\n",
      "Processing prompt 25515\n",
      "Session 25515 compressed!\n",
      "8 / 41 completed!\n",
      "Processed prompt 25515 in 8 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25555 started!\n",
      "Processing prompt 25555\n",
      "Session 25555 compressed!\n",
      "9 / 41 completed!\n",
      "Processed prompt 25555 in 6 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25521 started!\n",
      "Processing prompt 25521\n",
      "Session 25521 compressed!\n",
      "10 / 41 completed!\n",
      "Processed prompt 25521 in 6 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25503 started!\n",
      "Processing prompt 25503\n",
      "Session 25503 compressed!\n",
      "11 / 41 completed!\n",
      "Processed prompt 25503 in 9 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25526 started!\n",
      "Processing prompt 25526\n",
      "Session 25526 compressed!\n",
      "12 / 41 completed!\n",
      "Processed prompt 25526 in 6 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25597 started!\n",
      "Processing prompt 25597\n",
      "Session 25597 compressed!\n",
      "13 / 41 completed!\n",
      "Processed prompt 25597 in 17 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25530 started!\n",
      "Processing prompt 25530\n",
      "Session 25530 compressed!\n",
      "14 / 41 completed!\n",
      "Processed prompt 25530 in 9 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25617 started!\n",
      "Processing prompt 25617\n",
      "Session 25617 compressed!\n",
      "15 / 41 completed!\n",
      "Processed prompt 25617 in 11 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25550 started!\n",
      "Processing prompt 25550\n",
      "Session 25550 compressed!\n",
      "16 / 41 completed!\n",
      "Processed prompt 25550 in 14 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25598 started!\n",
      "Processing prompt 25598\n",
      "Session 25598 compressed!\n",
      "17 / 41 completed!\n",
      "Processed prompt 25598 in 9 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25611 started!\n",
      "Processing prompt 25611\n",
      "Session 25611 compressed!\n",
      "18 / 41 completed!\n",
      "Processed prompt 25611 in 6 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25652 started!\n",
      "Processing prompt 25652\n",
      "Session 25652 compressed!\n",
      "19 / 41 completed!\n",
      "Processed prompt 25652 in 14 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25600 started!\n",
      "Processing prompt 25600\n",
      "Session 25600 compressed!\n",
      "20 / 41 completed!\n",
      "Processed prompt 25600 in 13 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25630 started!\n",
      "Processing prompt 25630\n",
      "Session 25630 compressed!\n",
      "21 / 41 completed!\n",
      "Processed prompt 25630 in 5 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25426 started!\n",
      "Processing prompt 25426\n",
      "Session 25426 compressed!\n",
      "22 / 41 completed!\n",
      "Processed prompt 25426 in 11 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25631 started!\n",
      "Processing prompt 25631\n",
      "Session 25631 compressed!\n",
      "23 / 41 completed!\n",
      "Processed prompt 25631 in 9 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25636 started!\n",
      "Processing prompt 25636\n",
      "Session 25636 compressed!\n",
      "24 / 41 completed!\n",
      "Processed prompt 25636 in 6 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25744 started!\n",
      "Processing prompt 25744\n",
      "Session 25744 compressed!\n",
      "25 / 41 completed!\n",
      "Processed prompt 25744 in 8 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25367 started!\n",
      "Processing prompt 25367\n",
      "Error processing prompt 25367\n",
      "Unterminated string starting at: line 3 column 46 (char 75)\n",
      "=-=-=-=-=-=-=\n",
      "Session 25624 started!\n",
      "Processing prompt 25624\n",
      "Session 25624 compressed!\n",
      "27 / 41 completed!\n",
      "Processed prompt 25624 in 9 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25682 started!\n",
      "Processing prompt 25682\n",
      "Session 25682 compressed!\n",
      "28 / 41 completed!\n",
      "Processed prompt 25682 in 13 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25774 started!\n",
      "Processing prompt 25774\n",
      "Error processing prompt 25774\n",
      "Unterminated string starting at: line 29 column 36 (char 1886)\n",
      "=-=-=-=-=-=-=\n",
      "Session 25818 started!\n",
      "Processing prompt 25818\n",
      "Session 25818 compressed!\n",
      "30 / 41 completed!\n",
      "Processed prompt 25818 in 7 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25823 started!\n",
      "Processing prompt 25823\n",
      "Session 25823 compressed!\n",
      "31 / 41 completed!\n",
      "Processed prompt 25823 in 11 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25821 started!\n",
      "Processing prompt 25821\n",
      "Session 25821 compressed!\n",
      "32 / 41 completed!\n",
      "Processed prompt 25821 in 8 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25844 started!\n",
      "Processing prompt 25844\n",
      "Session 25844 compressed!\n",
      "33 / 41 completed!\n",
      "Processed prompt 25844 in 7 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25763 started!\n",
      "Processing prompt 25763\n",
      "Session 25763 compressed!\n",
      "34 / 41 completed!\n",
      "Processed prompt 25763 in 8 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25886 started!\n",
      "Processing prompt 25886\n",
      "Session 25886 compressed!\n",
      "35 / 41 completed!\n",
      "Processed prompt 25886 in 12 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25798 started!\n",
      "Processing prompt 25798\n",
      "Session 25798 compressed!\n",
      "36 / 41 completed!\n",
      "Processed prompt 25798 in 5 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25802 started!\n",
      "Processing prompt 25802\n",
      "Session 25802 compressed!\n",
      "37 / 41 completed!\n",
      "Processed prompt 25802 in 7 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25926 started!\n",
      "Processing prompt 25926\n",
      "Session 25926 compressed!\n",
      "38 / 41 completed!\n",
      "Processed prompt 25926 in 8 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25927 started!\n",
      "Processing prompt 25927\n",
      "Session 25927 compressed!\n",
      "39 / 41 completed!\n",
      "Processed prompt 25927 in 8 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25865 started!\n",
      "Processing prompt 25865\n",
      "Session 25865 compressed!\n",
      "40 / 41 completed!\n",
      "Processed prompt 25865 in 7 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Session 25925 started!\n",
      "Processing prompt 25925\n",
      "Session 25925 compressed!\n",
      "41 / 41 completed!\n",
      "Processed prompt 25925 in 6 seconds\n",
      "=-=-=-=-=-=-=\n",
      "Processed all prompts in 381 seconds\n"
     ]
    }
   ],
   "source": [
    "id_sessions = small_sessions_df[\"id_session\"].unique()\n",
    "\n",
    "total = len(id_sessions)\n",
    "time_all = 0\n",
    "sessions_with_error = []\n",
    "\n",
    "for index, id_session in enumerate(id_sessions):\n",
    "    print(f'Session {id_session} started!')\n",
    "\n",
    "    if os.path.exists(f'./small_responses_v2/{id_session}.json'):\n",
    "        print(f\"Prompt {id_session} already processed\")\n",
    "        print(\"=-=-=-=-=-=-=\")\n",
    "        continue\n",
    "\n",
    "    session_df = small_sessions_df[small_sessions_df[\"id_session\"] == id_session]\n",
    "    \n",
    "    if session_df[\"speaker_name\"].isnull().values.all():\n",
    "        print(f'Session {id_session} ignored!')\n",
    "        sessions_with_error.append(id_session)\n",
    "        print('=-=-=-=-=')\n",
    "        continue\n",
    "\n",
    "    prompt = summarization_prompt_for_stances('parliamentary session', session_df)\n",
    "\n",
    "    print(f\"Processing prompt {id_session}\")\n",
    "    try:\n",
    "        response_json = get_completion(prompt)\n",
    "    except Exception as e:\n",
    "        sessions_with_error.append(int(id_session))\n",
    "\n",
    "        print(f\"Error processing prompt {id_session}\")\n",
    "        print(e)\n",
    "        print(\"=-=-=-=-=-=-=\")\n",
    "        continue\n",
    "\n",
    "    elapsed_time = response_json['response_elapsed_time']\n",
    "    time_all += elapsed_time\n",
    "\n",
    "    with open(f'./responses_v2/{id_session}.json', 'w') as file:\n",
    "        json.dump(response_json, file)\n",
    "    \n",
    "    print(f'Session {id_session} compressed!')\n",
    "    print(f'{index + 1} / {total} completed!')\n",
    "    print(f\"Processed prompt {id_session} in {int(elapsed_time)} seconds\")\n",
    "    print(\"=-=-=-=-=-=-=\")\n",
    "    time.sleep(10)\n",
    "\n",
    "print(f\"Processed all prompts in {int(time_all)} seconds\")\n",
    "#save in a file the time it took to process all the prompts\n",
    "with open(f'./small_responses_v2/processing_time.json', 'w') as file:\n",
    "    json.dump({\n",
    "        'processing_time': time_all\n",
    "    }, file)\n",
    "\n",
    "# Save in a file the sessions that had an error\n",
    "with open(f'./small_responses_v2/sessions_with_error.json', 'w') as file:\n",
    "    json.dump({\n",
    "        'sessions_with_error': sessions_with_error\n",
    "    }, file)\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
